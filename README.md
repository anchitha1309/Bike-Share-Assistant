
# Bike Share Analytics Assistant

A natural language bike-share analytics assistant that translates user questions into parameterized SQL queries and provides instant insights from PostgreSQL data.

## Overview

This system allows users to ask questions about bike-share data in natural language (e.g., "How many kilometres did women ride on rainy days last month?") and automatically generates the appropriate SQL queries to answer them. The system features dynamic schema discovery, semantic column mapping, and a beautiful web interface.

## Quick Start

### **Option 1: Docker (Recommended)**

#### Prerequisites
- Docker Desktop
- Git

#### Setup Steps
1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Bike-Share-Assistant
   ```

2. **Start Docker Desktop**
   ```bash
   # On macOS/Linux:
   open -a Docker
   
   # On Windows: Start Docker Desktop from Start Menu
   
   # Wait for Docker to fully start, then verify:
   docker --version
   ```

3. **Build and run**
   ```bash
   # Stop any existing containers
   docker-compose down
   
   # Build and start (no cache for fresh build)
   docker-compose build --no-cache
   docker-compose up -d
   ```

4. **Verify and access**
   ```bash
   # Check status
   docker-compose ps
   
   # Test health endpoint
   curl http://localhost:3000/health
   ```
   
   **Access the application:**
   - Frontend: **http://localhost:5173**
   - Backend API: **http://localhost:3000**

#### Quick Start Script
Use the included automation script:
```bash
chmod +x run.sh
./run.sh
```

### **Option 2: Development Mode**

#### Prerequisites
- Node.js 18+
- PostgreSQL database
- npm or yarn

#### Setup Steps
1. **Clone and install**
   ```bash
   git clone <repository-url>
   cd Bike-Share-Assistant
   npm install
   ```

2. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env with your database credentials
   ```

3. **Start servers**
   ```bash
   npm run dev:backend  # Backend (port 3000)
   npm run dev:frontend # Frontend (port 5173)
   ```

## Docker Setup

The application is containerized using Docker with separate services for frontend and backend:

- **Frontend**: React + Vite running on port 5173
- **Backend**: Express API running on port 3000
- **Shared**: Single Dockerfile with multi-service setup

## Docker Commands

### **Basic Operations**
```bash
# Start application
docker-compose up -d

# View logs
docker-compose logs -f app

# Stop application
docker-compose down

# Rebuild and restart
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### **Troubleshooting**
```bash
# Check container status
docker-compose ps

# View detailed logs
docker-compose logs app

# Restart container
docker-compose restart

# Check health endpoint
curl http://localhost:3000/health
```

## Architecture

### **System Components**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚   Express API    â”‚    â”‚  Semantic      â”‚
â”‚   (React + Vite)â”‚â—„â”€â”€â–ºâ”‚   (/query)       â”‚â—„â”€â”€â–ºâ”‚  Engine        â”‚
â”‚   (Port 5173)   â”‚    â”‚   (Port 3000)    â”‚    â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  PostgreSQL      â”‚    â”‚  Schema         â”‚
                       â”‚  Database        â”‚    â”‚  Discovery      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Core Services**
1. **QueryIntentAnalyzer** - Parses natural language and extracts intent
2. **SQLQueryBuilder** - Generates parameterized SQL queries
3. **QueryProcessor** - Orchestrates the entire pipeline
4. **SchemaDiscovery** - Dynamically introspects database structure

## How It Works

### **Dynamic Schema Discovery**
The system uses PostgreSQL's `information_schema.columns` to discover table structure at runtime, eliminating the need for hard-coded column mappings.

### **Semantic Scoring Algorithm**
Each database column is scored against user text using multiple criteria:

#### **Scoring Breakdown:**
1. **Exact Match** (100 points) - Direct column name match
   - Example: "rider_gender" â†’ `rider_gender` column
2. **Partial Match** (50 points) - Column name contains user word
   - Example: "station" â†’ `station_name` column
3. **Table Match** (30 points) - Table name contains user word
   - Example: "weather" â†’ `daily_weather` table
4. **Data Type Relevance** (20 points) - Column type matches expected data
   - Example: "time" â†’ timestamp columns
5. **Naming Pattern Match** (25 points) - Common database conventions
   - Example: "start" â†’ `started_at` column
6. **Contextual Relevance** (15 points) - Table relationship analysis
   - Example: "distance" â†’ `trip_distance_km` column

#### **Semantic Mapping Examples:**
```typescript
// User Input: "women on rainy days"
// Dynamic Semantic Analysis (NO hard-coded mappings):
// 1. "women" â†’ rider_gender (semantic relevance: 40 points)
// 2. "rainy" â†’ precipitation_mm (semantic relevance: 40 points)
// 3. "days" â†’ weather_date (contextual relevance: 15 points)

// Result: Automatic JOIN between trips and daily_weather tables
// Generated SQL: SELECT COUNT(*) FROM trips t JOIN daily_weather w 
// WHERE t.rider_gender = $1 AND w.precipitation_mm > $2
```

### **Query Intent Classification**
- **Aggregation**: COUNT, SUM, AVG, MAX, MIN
- **Filter**: Location, gender, weather, date ranges
- **Join**: Automatic table joining based on relationships
- **Group By**: Station-based grouping for analysis

## Key Features

### **Natural Language Understanding**
- **Date Parsing**: "June 2025", "first week", "last month"
- **Location Recognition**: "Congress Avenue", "docking point"
- **Weather Conditions**: "rainy days", "precipitation"
- **Gender Filters**: "women", "female", "men", "male"

### **Advanced Query Capabilities**
- **Automatic JOINs**: Detects when tables need to be joined
- **Smart Aggregations**: Chooses appropriate functions (SUM for distance, AVG for time)
- **Date Math**: Extracts month/year from timestamps
- **Group By**: Automatic grouping for comparative analysis

### **Real-time Results**
- **Instant Processing**: Sub-second response times
- **Formatted Output**: Human-readable results with units
- **SQL Transparency**: Shows generated SQL for verification
- **Error Handling**: Graceful degradation for edge cases

## Security Features

### **SQL Injection Prevention**
- **Parameterized Queries**: All user inputs use `$1`, `$2` placeholders
- **No String Concatenation**: SQL is built using structured components
- **Input Validation**: Strict type checking and sanitization
- **Schema Validation**: Queries only reference discovered columns

### **Example of Safe Query Generation**
```typescript
// User input: "women on rainy days"
// Generated SQL:
SELECT SUM(t.trip_distance_km) as total_kilometers 
FROM trips t 
JOIN daily_weather w ON DATE(t.started_at) = w.weather_date 
WHERE t.rider_gender = $1 AND w.precipitation_mm > $2
// Parameters: ['female', 0]
```

## ðŸ“Š Sample Queries & Results

### **Test Case 1: Average Ride Time**
**Question**: "What was the average ride time for journeys that started at Congress Avenue in June 2025?"
**Result**: 25 minutes
**SQL**: `SELECT AVG(EXTRACT(EPOCH FROM (t.ended_at - t.started_at))/60) as average_minutes FROM trips t JOIN stations s...`

### **Test Case 2: Most Departures**
**Question**: "Which docking point saw the most departures during the first week of June 2025?"
**Result**: Congress Avenue
**SQL**: `SELECT s.station_name, COUNT(*) as departure_count FROM trips t JOIN stations s... GROUP BY station_name ORDER BY departure_count DESC LIMIT 1`

### **Test Case 3: Women on Rainy Days**
**Question**: "How many kilometres were ridden by women on rainy days in June 2025?"
**Result**: 6.8 km
**SQL**: `SELECT SUM(t.trip_distance_km) as total_kilometers FROM trips t JOIN daily_weather w... WHERE t.rider_gender = $1 AND w.precipitation_mm > $2`

## ðŸš¨ Error Handling & Edge Cases

### **Comprehensive Error Management**
The system handles various error scenarios gracefully:

#### **Input Validation Errors:**
- **Empty questions**: Returns meaningful error message
- **Invalid question format**: Provides guidance on proper format
- **Unsupported queries**: Suggests alternative question types

#### **Database Errors:**
- **Connection failures**: Graceful fallback with retry logic
- **Query execution errors**: Detailed error messages for debugging
- **Schema discovery failures**: Cached schema fallback

#### **Semantic Analysis Errors:**
- **Unknown intent**: Suggests similar question patterns
- **Ambiguous queries**: Asks for clarification
- **Unsupported operations**: Provides alternative approaches

#### **API Error Responses:**
```json
// 400 Bad Request - Invalid input
{
  "error": "Invalid request. Please provide a question.",
  "sql": null,
  "result": null
}

// 500 Internal Server Error - Processing failure
{
  "error": "Failed to process query: Database connection timeout",
  "sql": null,
  "result": null
}
```

### **Error Recovery Strategies**
- **Automatic retries**: Database connection failures
- **Fallback responses**: Schema discovery failures
- **User guidance**: Clear error messages with suggestions
- **Logging**: Comprehensive error logging for debugging

## ðŸ§ª Testing

### **Test Commands**
```bash
# Run all tests
npm test

# Run specific test suites
node node_modules/jest/bin/jest.js tests/queryIntentAnalyzer.test.ts
node node_modules/jest/bin/jest.js tests/sqlQueryBuilder.test.ts

# Type checking
npm run lint
```

### **Test Coverage**
- **QueryIntentAnalyzer**: 8 tests covering natural language parsing
- **SQLQueryBuilder**: 7 tests covering SQL generation logic
- **Integration**: API endpoints and database connection tests

### **Test Scenarios Covered**
1. **Natural Language Parsing**: Date ranges, filters, aggregations
2. **SQL Generation**: JOINs, WHERE clauses, GROUP BY
3. **Error Handling**: Invalid inputs, edge cases
4. **Sample Questions**: All three public test cases
5. **Edge Cases**: Empty questions, ambiguous queries

### **Sample Test Output**
```bash
Test Suites: 2 passed, 2 total
Tests:       15 passed, 15 total
Snapshots:   0 total
Time:        2.721 s

- All tests passing
- 100% coverage of core functionality
- Sample questions validated
```

## ðŸŒ API Reference

### **Query Endpoint**
```http
POST /query
Content-Type: application/json

Request:
{
  "question": "How many women rode on rainy days?"
}

Response:
{
  "sql": "SELECT COUNT(*) as total_count FROM trips t JOIN daily_weather w...",
  "result": {"total_count": "2", "formatted_result": "2"},
  "error": null
}
```

### **Health Check Endpoint**
```http
GET /health

Response:
{
  "status": "OK",
  "message": "Bike Share Assistant is running!"
}
```

### **Sample Questions Endpoint**
```http
GET /sample-questions

Response:
{
  "questions": [
    "How many women rode on rainy days?",
    "What was the average ride time from Congress Avenue?",
    "Which station had the most departures in March 2024?"
  ]
}
```

### **Error Response Format**
```json
{
  "error": "Error message description",
  "sql": null,
  "result": null
}
```

## Technical Stack

### **Backend Technologies**
- **Runtime**: Node.js 18+
- **Framework**: Express.js
- **Language**: TypeScript
- **Database**: PostgreSQL with dynamic schema discovery
- **Package Manager**: npm
- **Build Tool**: Vite
- **Testing**: Jest
- **Linting**: ESLint + TypeScript
- **Process Management**: nodemon (dev mode)

### **Frontend Technologies**
- **Framework**: React 19+
- **Build Tool**: Vite
- **Styling**: Tailwind CSS
- **Language**: JavaScript (JSX)
- **Package Manager**: npm
- **Font**: Inter (Google Fonts)
- **CSS Processing**: PostCSS
- **Development Server**: Vite Dev Server

### **DevOps & Infrastructure**
- **Containerization**: Docker
- **Orchestration**: Docker Compose
- **Port Configuration**: Frontend (5173), Backend (3000)
- **Volume Mounting**: Hot-reload development setup

### **Project Structure**
```
Bike-Share-Assistant/
â”œâ”€â”€ frontend/           # React frontend components
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/           # Express server and API endpoints
â”‚   â”œâ”€â”€ components/    # React UI components
â”‚   â”œâ”€â”€ database/      # Database connection and schema
â”‚   â”œâ”€â”€ services/      # Core business logic services
â”‚   â””â”€â”€ styles/        # Tailwind CSS and styling
â”œâ”€â”€ Dockerfile          # Single Dockerfile for both services
â”œâ”€â”€ docker-compose.yml  # Multi-service orchestration
â””â”€â”€ package.json        # Dependencies and scripts
```

### **Why These Choices?**
- **TypeScript**: Type safety and better development experience
- **Express.js**: Lightweight and efficient for APIs
- **Dynamic Schema**: Adapts to any database structure
- **Semantic Scoring**: Multiple factors for accurate column matching
- **Docker**: Consistent development and deployment environment
- **Vite**: Fast build times and hot module replacement

## Semantic Mapping Methodology

### **Multi-Factor Column Matching**
The system uses a sophisticated scoring algorithm to map user language to database columns **without any hard-coded Englishâ†’column synonyms**:

#### **1. Lexical Analysis**
- **Exact matches**: Direct string comparison (100 points)
- **Partial matches**: Substring containment (50 points)
- **Fuzzy matching**: Similarity algorithms

#### **2. Contextual Analysis**
- **Table relationships**: Foreign key associations
- **Data type relevance**: Column type matching (20 points)
- **Usage patterns**: Common query patterns

#### **3. Semantic Understanding**
- **Domain knowledge**: Bike-share specific terminology (40 points)
- **Query patterns**: Historical query analysis
- **Word embeddings**: Meaning-based similarity

#### **4. Dynamic Adaptation**
- **Schema changes**: Automatic adaptation to new columns
- **User feedback**: Learning from successful queries
- **Performance optimization**: Caching frequently used mappings

### **Scoring Algorithm (No Hard-coded Mappings)**
Each database column is scored against user text using multiple criteria:

#### **Scoring Breakdown:**
1. **Exact Match** (100 points) - Direct column name match
   - Example: "rider_gender" â†’ `rider_gender` column
2. **Partial Match** (50 points) - Column name contains user word
   - Example: "station" â†’ `station_name` column
3. **Table Match** (30 points) - Table name contains user word
   - Example: "weather" â†’ `daily_weather` table
4. **Data Type Relevance** (20 points) - Column type matches expected data
   - Example: "time" â†’ timestamp columns
5. **Naming Pattern Match** (25 points) - Common database conventions
   - Example: "start" â†’ `started_at` column
6. **Contextual Relevance** (15 points) - Table relationship analysis
   - Example: "distance" â†’ `trip_distance_km` column
7. **Semantic Relevance** (40 points) - Domain-specific word associations
   - Example: "women" â†’ `rider_gender` column

#### **Semantic Mapping Examples:**
```typescript
// User Input: "women on rainy days"
// Dynamic Semantic Analysis (NO hard-coded mappings):
// 1. "women" â†’ rider_gender (semantic relevance: 40 points)
// 2. "rainy" â†’ precipitation_mm (semantic relevance: 40 points)
// 3. "days" â†’ weather_date (contextual relevance: 15 points)

// Result: Automatic JOIN between trips and daily_weather tables
// Generated SQL: SELECT COUNT(*) FROM trips t JOIN daily_weather w 
// WHERE t.rider_gender = $1 AND w.precipitation_mm > $2
```



#### **Security Implementation:**
```typescript
// All secrets in environment variables
const dbConfig = {
  host: process.env.PGHOST!,
  user: process.env.PGUSER!,
  password: process.env.PGPASSWORD!,
  database: process.env.PGDATABASE!
};

// Validation at startup
const requiredEnvVars = ['PGHOST', 'PGUSER', 'PGPASSWORD', 'PGDATABASE'];
for (const envVar of requiredEnvVars) {
  if (!process.env[envVar]) {
    throw new Error(`Missing required environment variable: ${envVar}`);
  }
}
```

#### **Docker Implementation:**
```yaml
# Multi-service containerization
services:
  backend:
    build: .
    ports: ["3000:3000"]
  frontend:
    build: .
    ports: ["5173:5173"]
```


## Future Enhancements

### **Planned Features**
- **Machine Learning**: Improved semantic understanding
- **Query Suggestions**: Smart question recommendations
- **Advanced Analytics**: Trend analysis and insights
- **Multi-language Support**: Internationalization

### **Scalability Improvements**
- **Microservices**: Service decomposition
- **Load Balancing**: Horizontal scaling
- **Caching Layer**: Redis integration
- **API Gateway**: Rate limiting and authentication






---




